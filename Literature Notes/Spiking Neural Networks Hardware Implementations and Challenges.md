Title: Spiking Neural Networks Hardware Implementations and Challenges
Author: MAXENCE BOUVIER, ALEXANDRE VALENTIAN, THOMAS MESQUIDA,FRANCOIS RUMMENS, MARINA REYBOZ, ELISA VIANELLO, and EDITH BEIGNE
Topic: #neuromorphiccomputing #spikingneuralnetworks 
Publication date: 2019
Retrieved date: 21-06-2022 

### Background
- [[survey]] on [[spiking neural network]] and [[neuromorphic computing]] which are already major research field for both academic and industrial actors.

### Method
- Present the [[state of the art]] of hardware implementations of a [[spiking neural network]] and the current trends from model selection to training mechanisms. A general framework is presented with case by case particularities.

### Results
- [[algoritm to hardware mapping]] strategies are introduced
- [[spiking neural network]] generally perform worse than [[conventional neural network]] on formal datasets (CIFAR0-10, MNIST, ImageNet) but better on [[event-driven]] datasets.
- [[fault-tolerance]] techniques for SNNs and ANNs are mentioned
- supervised learning of SNNs is starting to enable [[spiking neural network]] to reach accuracies equivalent to the ones of [[conventional neural network]].

### Data 
- Uses a lot of references from literature (survey paper)

### Conclusions
- Dedicated SNNs outperform ANNs on MNIST
- Both in hardware and software there are still steps to be taken
- General development is in digital [[neuromorphic computing]]

### Significance
- Survey of current (2019) [[state of the art]] of [[neuromorphic computing]] and [[spiking neural network]]

### My Notes
- Useful figure for [[spiking neural network]] 
![[Pasted image 20220621104154.png]]
- [[Von Neumann bottleneck]]
- Describes concept of [[neuroplasticity]] and potential for [[fault-tolerance]]
- Describes concept of [[spike timing dependent plasticity]]
- 